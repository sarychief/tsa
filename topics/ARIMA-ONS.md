## Идея

### ARIMA - онлайн шаг ньютона (ONS)

Ключевая идея: Аппроксимировать исходную $\text{ARIMA(p,d,q)}$ другой моделью $\text{ARIMA(k+m, d, 0)}$ в которой нет шума $\epsilon$, где $m \in N$ - константа-параметр

- $\mathcal{K} = \{\gamma \in \mathbb{R}^{m+k}, |\gamma_j| \le 1, j=1,...,m\}$ - вектор коэффициентов модели $\text{ARIMA}(m+k, d, 0)$
- $D = 2c * \sqrt{m + k}$ - диаметр (?) $\mathcal{K}$
- $G =||\nabla \ell^m_t(\gamma)||,\forall\ t; \gamma \in \mathcal{K}$
- $\lambda$ - параметр экспоненциальной вогнутости лосс-функции $\{\ell^m_t\}^T_{t=1}$ что гарантирует $e^{-\lambda\ell^m_{t}(\gamma)}$ является вогнутой для всех $t$
- $\lambda = \frac{1}{m+k}$ квадратичная потеря для частных случаев

Данный алгоритм итеративно оптимизирует векторы коэффициентов $\gamma^t$ адаптивной модели АРПСС

$\ell_t(X_t, (\sum^q_{i=1}\beta_i\epsilon_{t-i} + \sum^k_{i=1}\alpha_i\nabla^dX_{t-i} + \sum^{d-1}_{i=0}\nabla^iX_{t-1}))$ - loss f

$R_T = \sum^T_{t=1}\ell(X_t, \tilde X_t) - \min_{\alpha, \beta}\sum^T_{t=1}\ell_t(X_t, \tilde X_t(\alpha, \beta))$ - цель минисмизация потерь за время T

$\prod^{A_t}_{\mathcal{K}}(y) = \arg\min_{x\in\mathcal{K}}(y-x)^{\top}A_t(y-x)$ - сама проекция метода

Обратная матрица находится с помощью формулы Шермана-Моррисона


$\text{Algorithm 1 ARIMA-ONS(k, d, q)}$
$\text{Input: parameter k, d, m; learning rate}\ \eta\text{; initial}(m + k) \times (m + k)\ \text{matrix}\ A_0$
$\text{Set}\ m = \log_{\lambda_{\max}}((\text{TLM}_{\text{max}}q)^{-1})$
$\text{for t=1 to T-1 do}$
$\text{predict }\tilde X_t(\gamma^t)= \sum^{k+m}_{i=1}\gamma_i\nabla^dX_{t-1}+\sum^{d-1}_{i=0}\nabla^iX_{t-1}$
$\text{receive }X_t\text{ and incur loss } \ell^m_t(\gamma^t)$
$\text{Let }\nabla_t = \nabla\ell^m_t(\gamma^t), \text{update} A_t \leftarrow A_{t-1} + \nabla_t\nabla^{\top}_t$
$\text{Set }\gamma^{t+1}\leftarrow\prod^{t_t}_{\mathcal{K}}(\gamma^t - \frac{1}{\eta}A^{-1}_t\nabla_t)$
$\text{end for}$






---
## Алгоритм

Этот алгоритм представляет собой онлайн-оптимизацию параметров модели ARIMA (AutoRegressive Integrated Moving Average) с использованием метода оптимизации на основе шага Ньютона (ONS). Давайте разберем основные шаги алгоритма:

1. **Определение параметров:**
   - $\mathcal{K}$ - множество коэффициентов модели ARIMA$(m+k, d, 0)$, где $m$ - порядок авторегрессии, $k$ - порядок скользящего среднего, $d$ - порядок интегрирования.
   - $D$ - диаметр (возможно, нормированный) множества $\mathcal{K}$.
   - $G$ - норма градиента лосс-функции $\ell^m_t$ для текущего шага и текущего значения $\gamma$.
   - $\lambda$ - параметр экспоненциальной вогнутости лосс-функции.

2. **Инициализация:**
   - $A_0$ - начальная матрица размера $(m+k) \times (m+k)$.
   - $m$ вычисляется на основе параметра $\lambda_{\max}$ и максимального значения функции потерь.

3. **Основной цикл:**
   - Для каждого временного шага $t$:
     - Прогнозирование $\tilde X_t(\gamma^t)$ на основе текущих коэффициентов $\gamma^t$.
     - Получение фактического значения $X_t$ и вычисление функции потерь $\ell^m_t(\gamma^t)$.
     - Вычисление градиента $\nabla_t$ функции потерь и обновление матрицы $A_t$.
     - Выполнение проекции $\prod^{A_t}_{\mathcal{K}}(\gamma^t)$ для обновления коэффициентов $\gamma^{t+1}$.
     - Продолжение цикла для следующего временного шага.

4. **Проекция $\prod^{A_t}_{\mathcal{K}}(y)$:**
   - Это операция проекции точки $y$ на множество $\mathcal{K}$ с использованием матрицы $A_t$. 

5. **Обновление матрицы $A_t$:**
   - Используется формула Шермана-Моррисона для обновления обратной матрицы.

6. **Оптимизация коэффициентов $\gamma$:**
   - Используется метод оптимизации на основе шага Ньютона с использованием матрицы $A_t$ и градиента $\nabla_t$.

Алгоритм итеративно обновляет параметры модели ARIMA, чтобы минимизировать функцию потерь в онлайн-режиме.

